{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"deletable": false,
				"editable": false,
				"trusted": true
			},
			"source": [
				"\n",
				"# How to use Great Expectations with AWS Glue Data Catalog\n",
				"\n",
				"In this notebook, we will walk through the steps-by-steps to setup Great Expectations with AWS Glue Data Catalog. Before you can start running this notebook, you must start an interactive session."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 0. Setup AWS Glue Interactive Session\n",
				"\n",
				"Before starting coding, be aware that there are a few options to set up an AWS Glue interactive session. In the following code cell, we are using some of them. Refer to the [AWS glue interactive session documentation](https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions-magics.html) for a complete view of the options available. \n",
				"\n",
				"Run the next code cell to setup the interactive session:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true
			},
			"outputs": [],
			"source": [
				"%additional_python_modules great_expectations\n",
				"%glue_version 3.0\n",
				"%number_of_workers 2"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Once you run the cell, the interactive session will be configured to use Glue 3.0, allocate 2 DPUs and install the Great Expectations package. Feel free to add or modify this setup as you like. The interactive session will not be created until we execute some code. Let’s start the session by running the following code cell to import some standard Glue libraries:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"outputs": [],
			"source": [
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"\n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 1. Create a Data Context\n",
				"\n",
				"For the sake of simplicity, we will create the Great Expectations Data Context in-memory using an Amazon S3 bucket as the store backend. The following example shows a Data Context configuration with a Spark datasource using the new AWS Glue Catalog Data Connector. Refer to the [following documentation](https://docs.greatexpectations.io/docs/guides/setup/configuring_data_contexts/how_to_instantiate_a_data_context_without_a_yml_file#2-pass-this-datacontextconfig-as-a-project_config-to-basedatacontext) for a better understanding.\n",
				"\n",
				"Run the following cell to create the Data Context:\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true
			},
			"outputs": [],
			"source": [
				"from great_expectations.data_context.types.base import DataContextConfig, DatasourceConfig, S3StoreBackendDefaults\n",
				"from great_expectations.data_context import BaseDataContext\n",
				"\n",
				"data_connectors = {\n",
				"    \"Runtime\": {\n",
				"        \"class_name\": \"RuntimeDataConnector\",\n",
				"        \"batch_identifiers\": [\"batch_id\"]\n",
				"    },\n",
				"    \"InferredGlue\": {\n",
				"        \"class_name\": \"InferredAssetAWSGlueDataCatalogDataConnector\"\n",
				"    },\n",
				"    \"ConfiguredGlue\": {\n",
				"        \"class_name\": \"ConfiguredAssetAWSGlueDataCatalogDataConnector\",\n",
				"        \"assets\": {\n",
				"            \"nyc_trip_data_asset\": {\n",
				"                \"table_name\": \"tb_nyc_trip_data\",\n",
				"                \"database_name\": \"db_ge_with_glue_demo\"\n",
				"            }\n",
				"        }\n",
				"    }\n",
				"}\n",
				"\n",
				"glue_data_source = DatasourceConfig(\n",
				"    class_name=\"Datasource\",\n",
				"    execution_engine={\n",
				"        \"class_name\": \"SparkDFExecutionEngine\",\n",
				"        \"force_reuse_spark_context\": True,\n",
				"    },\n",
				"    data_connectors=data_connectors\n",
				")\n",
				"\n",
				"metastore_backed = S3StoreBackendDefaults(default_bucket_name=\"great-expectations-glue-demo-<AWS_ACCOUNT_ID>-us-east-1\")\n",
				"\n",
				"data_context_config = DataContextConfig(\n",
				"    datasources={\"GlueDataSource\": glue_data_source},\n",
				"    store_backend_defaults=metastore_backed,\n",
				")\n",
				"\n",
				"context = BaseDataContext(project_config=data_context_config)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Now that we have a DataContext, we can check for the available data assets that the AWS Glue Data Connector was able to get from the Glue Catalog. Run the following code to get a list of available data assets:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true
			},
			"outputs": [],
			"source": [
				"from pprint import pprint\n",
				"\n",
				"pprint(context.get_available_data_asset_names())"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"If you have deployed the provided terraform code into you AWS account, you shall see that the InferredGlue connector returned the table *db_ge_with_glue_demo.tb_nyc_trip_data*. This table was created as part of the solution deployment. If you have more tables in the Glue Catalog, this connector shall output all of them. \n",
				"\n",
				"For a fine-grained control of what tables shall be available, use the **ConfiguredGlue** as an example. The Configured Connector requires that you define each database table you would like to validate. Be aware that the connector will not validate if, for any of the tables you define, the table exists nor if you have permissions to access it. Note: If you’re using AWS Lake Formation, check if the Glue IAM role has permissions to access it."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 2. Create Expectations\n",
				"\n",
				"Once you have the data context already setup, you can start to create the Expectations for our tables. Run the following code cell to create an Expectation Suite and a validator that we can use to create the expectations interactively. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true
			},
			"outputs": [],
			"source": [
				"from great_expectations.core.batch import BatchRequest\n",
				"\n",
				"expectation_suite_name = \"demo.taxi_trip.warning\"\n",
				"\n",
				"# Create Expectation Suite\n",
				"suite = context.create_expectation_suite(\n",
				"    expectation_suite_name=expectation_suite_name,\n",
				"    overwrite_existing=True,\n",
				")\n",
				"\n",
				"# Batch Request\n",
				"batch_request = BatchRequest(\n",
				"    datasource_name=\"GlueDataSource\",\n",
				"    data_connector_name=\"InferredGlue\",\n",
				"    data_asset_name=\"db_ge_with_glue_demo.tb_nyc_trip_data\",\n",
				"    data_connector_query={\n",
				"        \"batch_filter_parameters\": {\n",
				"            \"year\": \"2022\", \n",
				"            \"month\": \"03\"\n",
				"        }\n",
				"    }\n",
				")\n",
				"\n",
				"# Validator\n",
				"validator = context.get_validator(\n",
				"    batch_request=batch_request,\n",
				"    expectation_suite_name=expectation_suite_name,\n",
				")\n",
				"\n",
				"# Print\n",
				"df = validator.head(n_rows=5, fetch_all=False)\n",
				"pprint(df.info())"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Be aware that, the table we are using in this demo, is partitioned by year and month. Check the Table in Glue Data Catalog and you shall see that there are three partitions, named: 2022-01, 2022-02, 2022-03. For each table partition, the connector will create a batch identifier that allows us to filter a batch of data based on the partition values. In the code above, we are loading the partition 2022-03. If you do not specify the partition, the connector will get the first partition available by default. Note: filtering a partition is only available if your table is partitioned, otherwise, the table data will be loaded in a single batch.\n",
				"\n",
				"After running the code cell above, you can start to define the Expectations you want. Use the following code as example on how to define the Expectations and save it:\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true
			},
			"outputs": [],
			"source": [
				"# Define the Expectations\n",
				"validator.expect_table_row_count_to_be_between(min_value=1, max_value=None)\n",
				"validator.expect_column_values_to_not_be_null(column=\"vendorid\")\n",
				"validator.expect_column_values_to_be_between(column=\"passenger_count\", min_value=0, max_value=9)\n",
				"\n",
				"# Save the Expectation Suite\n",
				"validator.save_expectation_suite(discard_failed_expectations=False)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Validate that the Expectation Suite was saved into the S3 Bucket we have defined as our store backend. "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 3. Validate Data\n",
				"\n",
				"With the Expectation Suite already created, we can create a Checkpoint to validate data. Run the following code cell to create, save, and run the Checkpoint to get the validation results:"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true
			},
			"outputs": [],
			"source": [
				"from ruamel import yaml\n",
				"\n",
				"# Create Checkpoint\n",
				"my_checkpoint_name = \"demo.taxi_trip.checkpoint\" \n",
				"\n",
				"yaml_config = f\"\"\"\n",
				"name: {my_checkpoint_name}\n",
				"config_version: 1.0\n",
				"module_name: great_expectations.checkpoint\n",
				"class_name: Checkpoint\n",
				"run_name_template: \"%Y%m%d-TaxiTrip-GlueInferred\"\n",
				"action_list:\n",
				"  - name: store_validation_result\n",
				"    action:\n",
				"      class_name: StoreValidationResultAction\n",
				"  - name: update_data_docs\n",
				"    action:\n",
				"      class_name: UpdateDataDocsAction\n",
				"      site_names: []\n",
				"validations:\n",
				"  - batch_request:\n",
				"      datasource_name: GlueDataSource\n",
				"      data_connector_name: InferredGlue\n",
				"      data_asset_name: db_ge_with_glue_demo.tb_nyc_trip_data\n",
				"      data_connector_query:\n",
				"        batch_filter_parameters:\n",
				"          year: '2022'\n",
				"          month: '03'\n",
				"    expectation_suite_name: {expectation_suite_name}\n",
				"\"\"\"\n",
				"\n",
				"# Save Checkpoint\n",
				"_ = context.add_checkpoint(**yaml.load(yaml_config))\n",
				"\n",
				"# Run Checkpoint\n",
				"r = context.run_checkpoint(checkpoint_name=my_checkpoint_name)\n",
				"pprint(r)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"🚀🚀 Congratulations! 🚀🚀 You’ve successfully connected Great Expectations with your data through AWS Glue Data Catalog."
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"pygments_lexer": "python3",
			"version": "3.9.7"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
